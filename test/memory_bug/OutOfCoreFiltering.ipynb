{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from os.path import join, normpath\n",
    "\n",
    "sys.path.insert(0, normpath('..'))\n",
    "from aroma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    }
   ],
   "source": [
    "infile = join('MAC-M006_TASK_preproc.feat', 'filtered_func_data.nii.gz')\n",
    "outfile = 'ica_filter_out.nii.gz'\n",
    "mixfile = join('MAC-M006_TASK_preproc.feat', 'ICA_AROMA', 'melodic.ica', 'melodic_mix')\n",
    "mix = np.loadtxt(mixfile)\n",
    "indicesfile = join('MAC-M006_TASK_preproc.feat', 'ICA_AROMA', 'classified_motion_ICs.txt')\n",
    "denoise_indices = list(np.loadtxt(indicesfile, dtype=int, delimiter=',') - 1)\n",
    "print(len(denoise_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nii = nib.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 42, 1598)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598, 658)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8329113600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "mem = virtual_memory()\n",
    "mem.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.757092 Gi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "mem_gib = mem_bytes/(1024**3)\n",
    "print('%f Gi' % mem_gib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nii = nib.load(infile)\n",
    "data = nii.get_data().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bit of a problem - dataset is so large that can't load even a single copy with nibabel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "denoising(infile, outfile, mix=mix, denoise_indices=denoise_indices[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the image we can use the array proxy in nibabel to get just a part.\n",
    "```\n",
    "proxy_img = nib.load(example_file)\n",
    "vol1 = proxy_img.dataobj[..., 1]\n",
    "```\n",
    "NB the arrays will be in fortran order and indexed (x,y,z,t) so this will be the second time point\n",
    "\n",
    "We could take chunks of say 50 time points and write them to a numpy memmapped array so we then have a memmapped array to work on.\n",
    "\n",
    "The pinv in on the much smaller design matrix array so we can leave that.\n",
    "\n",
    "We then have to make sure that `pinv(design).dot(data)` ends up in another memmapped array without any in core intermediate - re could put `pinv(design)` into another memmapped array and asign to a third.\n",
    "\n",
    "\n",
    "Problem then is how do we write back the result? - ouch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "tmpd = mkdtemp()\n",
    "xfile = join(tmpd, 'xfile.dat')\n",
    "yfile = join(tmpd, 'yfile.dat')\n",
    "prodfile = join(tmpd, 'prodfile.dat')\n",
    "addfile = join(tmpd, 'addfile.dat')\n",
    "scalefile = join(tmpd, 'scalefile.dat')\n",
    "\n",
    "# Create large arrays x and y.\n",
    "# Note they are 1e4 not 1e6 b/c of memory issues creating random numpy matrices (CookieOfFortune) \n",
    "# However, the same principles apply to larger arrays\n",
    "x = np.random.randn(10000, 10000)\n",
    "y = np.random.randn(10000, 10000)\n",
    "\n",
    "# Create memory maps for x and y arrays\n",
    "xmap = np.memmap(xfile, dtype='float32', mode='w+', shape=x.shape)\n",
    "ymap = np.memmap(yfile, dtype='float32', mode='w+', shape=y.shape)\n",
    "\n",
    "# Fill memory maps with data\n",
    "xmap[:] = x[:]\n",
    "ymap[:] = y[:]\n",
    "\n",
    "# Create memory map for out of core dot product result\n",
    "prodmap = np.memmap(prodfile, dtype='float32', mode='w+', shape=x.shape)\n",
    "\n",
    "# Due out of core dot product and write data\n",
    "prodmap[:] = np.memmap.dot(xmap, ymap)\n",
    "\n",
    "# Create memory map for out of core addition result\n",
    "addmap = np.memmap(addfile, dtype='float32', mode='w+', shape=x.shape)\n",
    "\n",
    "# Due out of core addition and write data\n",
    "addmap[:] = xmap + ymap\n",
    "\n",
    "# Create memory map for out of core scaling result\n",
    "scalemap = np.memmap(scalefile, dtype='float32', mode='w+', shape=x.shape)\n",
    "\n",
    "# Define scaling constant\n",
    "scale = 1.3\n",
    "\n",
    "# Do out of corescaling and write data\n",
    "scalemap[:] = scale * xmap\n",
    "                     \n",
    "rmtree(tmpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 42, 1598)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1598, 42, 96, 96)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii = nib.load(infile)\n",
    "print(nii.shape)\n",
    "tuple(reversed(nii.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 42, 1598)\n",
      "(1598, 387072)\n",
      "(96, 96, 42, 1598)\n",
      "(1598, 387072)\n",
      "(96, 96, 42, 1598)\n",
      "(1598, 387072)\n",
      "(96, 96, 42, 1598)\n",
      "(1598, 387072)\n",
      "1 loop, best of 3: 1min 13s per loop\n"
     ]
    }
   ],
   "source": [
    "tmpd = mkdtemp()\n",
    "\n",
    "nii = nib.load(infile)\n",
    "print(nii.shape)\n",
    "\n",
    "datafile = join(tmpd, 'datafile.dat')\n",
    "data = np.memmap(datafile, dtype='float32', mode='w+', shape=tuple(reversed(nii.shape)), order='C')\n",
    "chunk = 500\n",
    "nx, ny, nz, nt = nii.shape\n",
    "nchunks = int(np.ceil(float(nt) / chunk))\n",
    "for i in range(nchunks):\n",
    "    if i == nchunks - 1:\n",
    "        data[i*chunk:] = nii.dataobj[..., i*chunk:].T\n",
    "    else:\n",
    "        data[i*chunk:(i+1)*chunk] = nii.dataobj[..., i*chunk:(i+1)*chunk].T\n",
    "\n",
    "data = data.reshape((nt, -1))\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "np.memmap.dot(xmap, ymap)\n",
    "prodfile = join(tmpd, 'prodfile.dat')\n",
    "prod = np.memmap(prodfile, dtype='float32', mode='w+', shape=tuple(reversed(nii.shape)), order='C')\n",
    "\n",
    "pinv(design).dot(data)[components]\n",
    "\n",
    "rmtree(tmpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
